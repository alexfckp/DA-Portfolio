{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72b68f6",
   "metadata": {},
   "source": [
    "# P3 · Forecasting / Predictive Baseline\n",
    "\n",
    "> **Case study notebook** — replace placeholders with your dataset and analysis.\n",
    "\n",
    "**Checklist**\n",
    "- [ ] Link to dataset and license\n",
    "- [ ] Problem statement & business context\n",
    "- [ ] Data dictionary & assumptions\n",
    "- [ ] Methodology overview (steps & scope)\n",
    "- [ ] Results (KPIs, visuals, tables)\n",
    "- [ ] Executive summary (non-technical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment & imports\n",
    "import os, sys, json, math, pathlib, sqlite3, itertools, statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local utils\n",
    "sys.path.append(str(pathlib.Path('../src').resolve()))\n",
    "from utils import ensure_dirs, load_csv, save_df, memory_report\n",
    "\n",
    "# Paths\n",
    "RAW = pathlib.Path('../data/raw')\n",
    "PROC = pathlib.Path('../data/processed')\n",
    "REPORTS = pathlib.Path('../reports')\n",
    "ensure_dirs(RAW, PROC, REPORTS)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475aaed9",
   "metadata": {},
   "source": [
    "## 1) Data Ingestion & Provenance\n",
    "\n",
    "- Describe the data source (URL, owner, update frequency).\n",
    "- Record the date/time pulled and version.\n",
    "- Save the raw snapshot under `data/raw/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load a CSV placed manually in data/raw\n",
    "# df_raw = load_csv(RAW / 'your_raw_file.csv')\n",
    "# display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad73e33",
   "metadata": {},
   "source": [
    "## 2) Data Quality & Cleaning\n",
    "\n",
    "Assess and fix:\n",
    "- Missingness, duplicates, types, outliers\n",
    "- Standardize categories, units, and date parsing\n",
    "- Create a data quality report (shape, null %, duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'df_raw' in globals():\n",
    "#     # Basic profile\n",
    "#     print('Shape:', df_raw.shape)\n",
    "#     nulls = df_raw.isna().mean().sort_values(ascending=False).to_frame('null_pct')\n",
    "#     display(nulls.head(20))\n",
    "#     dup_count = df_raw.duplicated().sum()\n",
    "#     print('Duplicates:', dup_count)\n",
    "#     display(df_raw.describe(include='all').T.head(20))\n",
    "#     memory_report(df_raw)\n",
    "# else:\n",
    "#     print('Place a dataset in data/raw and uncomment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402eae2c",
   "metadata": {},
   "source": [
    "## 3) Feature Engineering / Transformations\n",
    "\n",
    "- Create canonical keys, date parts, normalized metrics\n",
    "- Save cleaned dataset to `data/processed/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example transformation\n",
    "# df = df_raw.copy()\n",
    "# # df['date'] = pd.to_datetime(df['date'])\n",
    "# # df['month'] = df['date'].dt.to_period('M')\n",
    "# # Save processed\n",
    "# save_df(df, PROC / 'clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7567ac",
   "metadata": {},
   "source": [
    "## 4) EDA & KPIs\n",
    "\n",
    "- Univariate/bivariate analysis\n",
    "- Trend lines, distributions, categorical vs numeric\n",
    "- Define and compute KPIs relevant to the problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'df' in globals():\n",
    "#     # Example: histogram of a numeric column\n",
    "#     # df['some_numeric'].plot(kind='hist')\n",
    "#     # plt.show()\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641de49",
   "metadata": {},
   "source": [
    "## 5) (Optional) SQL Layer (for P2)\n",
    "\n",
    "- Create a local SQLite DB from the processed data\n",
    "- Write and document analytical queries/views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ab567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'df' in globals():\n",
    "#     conn = sqlite3.connect(PROC / 'project.db')\n",
    "#     df.to_sql('fact', conn, if_exists='replace', index=False)\n",
    "#     # Example analytical question:\n",
    "#     # q = '''\n",
    "#     # SELECT category, COUNT(*) as n, AVG(metric) as avg_metric\n",
    "#     # FROM fact GROUP BY 1 ORDER BY 2 DESC;\n",
    "#     # '''\n",
    "#     # print(pd.read_sql(q, conn).head())\n",
    "#     # conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3f4cb",
   "metadata": {},
   "source": [
    "## 6) (P3) Baseline Modeling\n",
    "\n",
    "- Choose a simple model (e.g., LinearRegression or LogisticRegression)\n",
    "- Split data, evaluate baseline metrics, analyze errors\n",
    "- Emphasize interpretability: coefficients/feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfda59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example baseline (uncomment and adapt)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# # y = df['target']; X = df.drop(columns=['target'])\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# # model = LinearRegression()\n",
    "# # model.fit(X_train, y_train)\n",
    "# # pred = model.predict(X_test)\n",
    "# # print('MAE:', mean_absolute_error(y_test, pred))\n",
    "# # print('R2:', r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646afdc9",
   "metadata": {},
   "source": [
    "## 7) (P4) Visualization Storytelling\n",
    "\n",
    "- What story are we telling? Who is the audience?\n",
    "- Build a few key visuals that track directly to the KPIs\n",
    "- Export images to `reports/` for the executive summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example export\n",
    "# fig = plt.figure()\n",
    "# df['some_numeric'].plot(kind='hist')\n",
    "# fig.savefig(REPORTS / 'figure_01.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c825ad5",
   "metadata": {},
   "source": [
    "## 8) Executive Summary (Non-Technical)\n",
    "\n",
    "- Context & objective (2–3 lines)\n",
    "- What we did (bulleted steps)\n",
    "- 3–5 key findings with impact\n",
    "- Next actions (clear, prioritized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1b4c3",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "- Data dictionary\n",
    "- Assumptions & limitations\n",
    "- Ethical & privacy considerations\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
